[DEBUG] CLIP Model = rn50 → Token Embed Dim: 512, Final LN Dim: 512
[DEBUG] PromptLearner proj layer = Linear | in: 512, out: 512
[DEBUG] Dummy Image Feature Shape: torch.Size([1, 1024])
[DEBUG] Text Feature Output (via proj) should match: 512
[WARNING] Feature dim mismatch! Image: 1024, Text: 512
BNNeck and ArcFace head registered (scale=20, margin=0.3)
CLIP text encoder unfrozen.
[Trainable] conv1.weight
[Trainable] bn1.weight
[Trainable] bn1.bias
[Trainable] conv2.weight
[Trainable] bn2.weight
[Trainable] bn2.bias
[Trainable] conv3.weight
[Trainable] bn3.weight
[Trainable] bn3.bias
[Trainable] layer1.0.conv1.weight
[Trainable] layer1.0.bn1.weight
[Trainable] layer1.0.bn1.bias
[Trainable] layer1.0.conv2.weight
[Trainable] layer1.0.bn2.weight
[Trainable] layer1.0.bn2.bias
[Trainable] layer1.0.conv3.weight
[Trainable] layer1.0.bn3.weight
[Trainable] layer1.0.bn3.bias
[Trainable] layer1.0.downsample.0.weight
[Trainable] layer1.0.downsample.1.weight
[Trainable] layer1.0.downsample.1.bias
[Trainable] layer1.1.conv1.weight
[Trainable] layer1.1.bn1.weight
[Trainable] layer1.1.bn1.bias
[Trainable] layer1.1.conv2.weight
[Trainable] layer1.1.bn2.weight
[Trainable] layer1.1.bn2.bias
[Trainable] layer1.1.conv3.weight
[Trainable] layer1.1.bn3.weight
[Trainable] layer1.1.bn3.bias
[Trainable] layer1.2.conv1.weight
[Trainable] layer1.2.bn1.weight
[Trainable] layer1.2.bn1.bias
[Trainable] layer1.2.conv2.weight
[Trainable] layer1.2.bn2.weight
[Trainable] layer1.2.bn2.bias
[Trainable] layer1.2.conv3.weight
[Trainable] layer1.2.bn3.weight
[Trainable] layer1.2.bn3.bias
[Trainable] layer2.0.conv1.weight
[Trainable] layer2.0.bn1.weight
[Trainable] layer2.0.bn1.bias
[Trainable] layer2.0.conv2.weight
[Trainable] layer2.0.bn2.weight
[Trainable] layer2.0.bn2.bias
[Trainable] layer2.0.conv3.weight
[Trainable] layer2.0.bn3.weight
[Trainable] layer2.0.bn3.bias
[Trainable] layer2.0.downsample.0.weight
[Trainable] layer2.0.downsample.1.weight
[Trainable] layer2.0.downsample.1.bias
[Trainable] layer2.1.conv1.weight
[Trainable] layer2.1.bn1.weight
[Trainable] layer2.1.bn1.bias
[Trainable] layer2.1.conv2.weight
[Trainable] layer2.1.bn2.weight
[Trainable] layer2.1.bn2.bias
[Trainable] layer2.1.conv3.weight
[Trainable] layer2.1.bn3.weight
[Trainable] layer2.1.bn3.bias
[Trainable] layer2.2.conv1.weight
[Trainable] layer2.2.bn1.weight
[Trainable] layer2.2.bn1.bias
[Trainable] layer2.2.conv2.weight
[Trainable] layer2.2.bn2.weight
[Trainable] layer2.2.bn2.bias
[Trainable] layer2.2.conv3.weight
[Trainable] layer2.2.bn3.weight
[Trainable] layer2.2.bn3.bias
[Trainable] layer2.3.conv1.weight
[Trainable] layer2.3.bn1.weight
[Trainable] layer2.3.bn1.bias
[Trainable] layer2.3.conv2.weight
[Trainable] layer2.3.bn2.weight
[Trainable] layer2.3.bn2.bias
[Trainable] layer2.3.conv3.weight
[Trainable] layer2.3.bn3.weight
[Trainable] layer2.3.bn3.bias
[Trainable] layer3.0.conv1.weight
[Trainable] layer3.0.bn1.weight
[Trainable] layer3.0.bn1.bias
[Trainable] layer3.0.conv2.weight
[Trainable] layer3.0.bn2.weight
[Trainable] layer3.0.bn2.bias
[Trainable] layer3.0.conv3.weight
[Trainable] layer3.0.bn3.weight
[Trainable] layer3.0.bn3.bias
[Trainable] layer3.0.downsample.0.weight
[Trainable] layer3.0.downsample.1.weight
[Trainable] layer3.0.downsample.1.bias
[Trainable] layer3.1.conv1.weight
[Trainable] layer3.1.bn1.weight
[Trainable] layer3.1.bn1.bias
[Trainable] layer3.1.conv2.weight
[Trainable] layer3.1.bn2.weight
[Trainable] layer3.1.bn2.bias
[Trainable] layer3.1.conv3.weight
[Trainable] layer3.1.bn3.weight
[Trainable] layer3.1.bn3.bias
[Trainable] layer3.2.conv1.weight
[Trainable] layer3.2.bn1.weight
[Trainable] layer3.2.bn1.bias
[Trainable] layer3.2.conv2.weight
[Trainable] layer3.2.bn2.weight
[Trainable] layer3.2.bn2.bias
[Trainable] layer3.2.conv3.weight
[Trainable] layer3.2.bn3.weight
[Trainable] layer3.2.bn3.bias
[Trainable] layer3.3.conv1.weight
[Trainable] layer3.3.bn1.weight
[Trainable] layer3.3.bn1.bias
[Trainable] layer3.3.conv2.weight
[Trainable] layer3.3.bn2.weight
[Trainable] layer3.3.bn2.bias
[Trainable] layer3.3.conv3.weight
[Trainable] layer3.3.bn3.weight
[Trainable] layer3.3.bn3.bias
[Trainable] layer3.4.conv1.weight
[Trainable] layer3.4.bn1.weight
[Trainable] layer3.4.bn1.bias
[Trainable] layer3.4.conv2.weight
[Trainable] layer3.4.bn2.weight
[Trainable] layer3.4.bn2.bias
[Trainable] layer3.4.conv3.weight
[Trainable] layer3.4.bn3.weight
[Trainable] layer3.4.bn3.bias
[Trainable] layer3.5.conv1.weight
[Trainable] layer3.5.bn1.weight
[Trainable] layer3.5.bn1.bias
[Trainable] layer3.5.conv2.weight
[Trainable] layer3.5.bn2.weight
[Trainable] layer3.5.bn2.bias
[Trainable] layer3.5.conv3.weight
[Trainable] layer3.5.bn3.weight
[Trainable] layer3.5.bn3.bias
[Trainable] layer4.0.conv1.weight
[Trainable] layer4.0.bn1.weight
[Trainable] layer4.0.bn1.bias
[Trainable] layer4.0.conv2.weight
[Trainable] layer4.0.bn2.weight
[Trainable] layer4.0.bn2.bias
[Trainable] layer4.0.conv3.weight
[Trainable] layer4.0.bn3.weight
[Trainable] layer4.0.bn3.bias
[Trainable] layer4.0.downsample.0.weight
[Trainable] layer4.0.downsample.1.weight
[Trainable] layer4.0.downsample.1.bias
[Trainable] layer4.1.conv1.weight
[Trainable] layer4.1.bn1.weight
[Trainable] layer4.1.bn1.bias
[Trainable] layer4.1.conv2.weight
[Trainable] layer4.1.bn2.weight
[Trainable] layer4.1.bn2.bias
[Trainable] layer4.1.conv3.weight
[Trainable] layer4.1.bn3.weight
[Trainable] layer4.1.bn3.bias
[Trainable] layer4.2.conv1.weight
[Trainable] layer4.2.bn1.weight
[Trainable] layer4.2.bn1.bias
[Trainable] layer4.2.conv2.weight
[Trainable] layer4.2.bn2.weight
[Trainable] layer4.2.bn2.bias
[Trainable] layer4.2.conv3.weight
[Trainable] layer4.2.bn3.weight
[Trainable] layer4.2.bn3.bias
[Trainable] attnpool.positional_embedding
[Trainable] attnpool.k_proj.weight
[Trainable] attnpool.k_proj.bias
[Trainable] attnpool.q_proj.weight
[Trainable] attnpool.q_proj.bias
[Trainable] attnpool.v_proj.weight
[Trainable] attnpool.v_proj.bias
[Trainable] attnpool.c_proj.weight
[Trainable] attnpool.c_proj.bias
Total trainable CLIP params: 102155689
[DEBUG] PromptLearner trainable params: 967680
[DEBUG] CLIP trainable params: 102155689
[Prompt] cached 890 frozen image feats
[Epoch 1] Avg Prompt Loss: 3.1156
new best prompt – 3.1156
[Epoch 2] Avg Prompt Loss: 2.7174
new best prompt – 2.7174
[Epoch 3] Avg Prompt Loss: 2.5894
new best prompt – 2.5894
[Epoch 4] Avg Prompt Loss: 2.3525
new best prompt – 2.3525
[Epoch 5] Avg Prompt Loss: 2.3056
new best prompt – 2.3056
[Epoch 6] Avg Prompt Loss: 2.1207
new best prompt – 2.1207
[Epoch 7] Avg Prompt Loss: 1.9612
new best prompt – 1.9612
[Epoch 8] Avg Prompt Loss: 1.7543
new best prompt – 1.7543
[Epoch 9] Avg Prompt Loss: 1.8868
[Epoch 10] Avg Prompt Loss: 1.9248
[Epoch 11] Avg Prompt Loss: 1.8071
[Epoch 12] Avg Prompt Loss: 1.6555
new best prompt – 1.6555
[Epoch 13] Avg Prompt Loss: 1.7381
[Epoch 14] Avg Prompt Loss: 1.6721
[Epoch 15] Avg Prompt Loss: 1.6358
new best prompt – 1.6358
[Epoch 16] Avg Prompt Loss: 1.5975
new best prompt – 1.5975
[Epoch 17] Avg Prompt Loss: 1.6845
[Epoch 18] Avg Prompt Loss: 1.6749
[Epoch 19] Avg Prompt Loss: 1.6247
[Epoch 20] Avg Prompt Loss: 1.5754
new best prompt – 1.5754
[Epoch 21] Avg Prompt Loss: 1.5271
new best prompt – 1.5271
[Epoch 22] Avg Prompt Loss: 1.5535
[Epoch 23] Avg Prompt Loss: 1.4311
new best prompt – 1.4311
[Epoch 24] Avg Prompt Loss: 1.4811
[Epoch 25] Avg Prompt Loss: 1.5063
[Epoch 26] Avg Prompt Loss: 1.5213
[Epoch 27] Avg Prompt Loss: 1.4824
[Epoch 28] Avg Prompt Loss: 1.4787
[Epoch 29] Avg Prompt Loss: 1.3358
new best prompt – 1.3358
[Epoch 30] Avg Prompt Loss: 1.5023
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0492
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0604
[ArcFace] Confidence: 0.0500
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0506
[Epoch 1] Learning Rate: 0.000006
[Epoch 1] Running validation...
[Epoch 1] Loss Breakdown: ID = 4.2642, Triplet = 0.0885, Center = 975.0601, i2t = 0.8717, t2i = 0.8666
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 51.70%
RANK5: 74.56%
RANK10: 80.74%
MAP: 61.83%
 New BEST Image model saved
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0497
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0543
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0527
[Epoch 2] Learning Rate: 0.000015
[Epoch 2] Running validation...
[Epoch 2] Loss Breakdown: ID = 4.2380, Triplet = 0.0388, Center = 979.2291, i2t = 1.0711, t2i = 1.1142
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 49.74%
RANK5: 76.83%
RANK10: 86.20%
MAP: 61.53%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0508
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0494
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0567
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0576
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0508
[Epoch 3] Learning Rate: 0.000020
[Epoch 3] Running validation...
[Epoch 3] Loss Breakdown: ID = 4.1888, Triplet = 0.1177, Center = 986.4890, i2t = 1.8903, t2i = 1.8570
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 46.65%
RANK5: 71.88%
RANK10: 81.67%
MAP: 58.36%
No improvement in loss. Patience counter: 2/5
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0571
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0608
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0495
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0586
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0500
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0490
[ArcFace] Confidence: 0.0554
[Epoch 4] Learning Rate: 0.000020
[Epoch 4] Running validation...
[Epoch 4] Loss Breakdown: ID = 4.1025, Triplet = 0.0002, Center = 966.9940, i2t = 0.4827, t2i = 0.4952
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 62.10%
RANK5: 85.79%
RANK10: 91.86%
MAP: 72.63%
 New BEST Image model saved
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0534
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0495
[ArcFace] Confidence: 0.0489
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0482
[ArcFace] Confidence: 0.0487
[ArcFace] Confidence: 0.0589
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0495
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0492
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0523
[Epoch 5] Learning Rate: 0.000020
[Epoch 5] Running validation...
[Epoch 5] Loss Breakdown: ID = 4.0487, Triplet = 0.0469, Center = 966.6228, i2t = 0.9567, t2i = 0.9904
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 65.71%
RANK5: 87.33%
RANK10: 93.61%
MAP: 75.25%
 New BEST Image model saved
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0497
[ArcFace] Confidence: 0.0483
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0485
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0505
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0539
[Epoch 6] Learning Rate: 0.000019
[Epoch 6] Running validation...
[Epoch 6] Loss Breakdown: ID = 4.0130, Triplet = 0.0613, Center = 952.9865, i2t = 1.5801, t2i = 1.6094
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 66.43%
RANK5: 86.61%
RANK10: 93.31%
MAP: 75.33%
 New BEST Image model saved
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0493
[ArcFace] Confidence: 0.0567
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0510
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0495
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0553
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0577
[ArcFace] Confidence: 0.0562
[Epoch 7] Learning Rate: 0.000019
[Epoch 7] Running validation...
[Epoch 7] Loss Breakdown: ID = 3.9686, Triplet = 0.0452, Center = 965.2615, i2t = 1.7237, t2i = 1.7332
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 73.43%
RANK5: 92.17%
RANK10: 97.32%
MAP: 81.54%
 New BEST Image model saved
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0612
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0628
[ArcFace] Confidence: 0.0588
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0589
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0571
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0610
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0635
[ArcFace] Confidence: 0.0618
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0567
[Epoch 8] Learning Rate: 0.000018
[Epoch 8] Running validation...
[Epoch 8] Loss Breakdown: ID = 3.8739, Triplet = 0.0113, Center = 942.3082, i2t = 1.2856, t2i = 1.2380
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 69.62%
RANK5: 90.94%
RANK10: 96.09%
MAP: 78.65%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0616
[ArcFace] Confidence: 0.0644
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0566
[ArcFace] Confidence: 0.0610
[ArcFace] Confidence: 0.0591
[ArcFace] Confidence: 0.0610
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0571
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0587
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0510
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0596
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0583
[Epoch 9] Learning Rate: 0.000018
[Epoch 9] Running validation...
[Epoch 9] Loss Breakdown: ID = 3.7722, Triplet = 0.0029, Center = 944.5200, i2t = 1.2770, t2i = 1.3618
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 78.48%
RANK5: 94.54%
RANK10: 96.91%
MAP: 85.32%
 New BEST Image model saved
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0614
[ArcFace] Confidence: 0.0591
[ArcFace] Confidence: 0.0607
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0598
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0627
[ArcFace] Confidence: 0.0566
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0632
[ArcFace] Confidence: 0.0598
[ArcFace] Confidence: 0.0588
[ArcFace] Confidence: 0.0593
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0631
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0628
[ArcFace] Confidence: 0.0593
[Epoch 10] Learning Rate: 0.000017
[Epoch 10] Running validation...
[Epoch 10] Loss Breakdown: ID = 3.8183, Triplet = 0.0234, Center = 931.9947, i2t = 1.0705, t2i = 1.1142
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 78.27%
RANK5: 91.66%
RANK10: 96.81%
MAP: 84.32%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0613
[ArcFace] Confidence: 0.0662
[ArcFace] Confidence: 0.0618
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0573
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0651
[ArcFace] Confidence: 0.0645
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0617
[ArcFace] Confidence: 0.0612
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0640
[ArcFace] Confidence: 0.0585
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0636
[Epoch 11] Learning Rate: 0.000016
[Epoch 11] Running validation...
[Epoch 11] Loss Breakdown: ID = 3.8008, Triplet = 0.0264, Center = 923.8116, i2t = 1.4200, t2i = 1.4856
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 73.74%
RANK5: 92.69%
RANK10: 97.73%
MAP: 81.93%
No improvement in loss. Patience counter: 2/5
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0587
[ArcFace] Confidence: 0.0594
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0560
[ArcFace] Confidence: 0.0618
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0623
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0605
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0608
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0619
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0667
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0604
[Epoch 12] Learning Rate: 0.000015
[Epoch 12] Running validation...
[Epoch 12] Loss Breakdown: ID = 3.7110, Triplet = 0.0339, Center = 939.6059, i2t = 1.6357, t2i = 1.6094
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 77.03%
RANK5: 93.31%
RANK10: 97.32%
MAP: 84.36%
No improvement in loss. Patience counter: 3/5
[ArcFace] Confidence: 0.0590
[ArcFace] Confidence: 0.0598
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0596
[ArcFace] Confidence: 0.0589
[ArcFace] Confidence: 0.0608
[ArcFace] Confidence: 0.0589
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0600
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0602
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0571
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0588
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0577
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0524
[Epoch 13] Learning Rate: 0.000014
[Epoch 13] Running validation...
[Epoch 13] Loss Breakdown: ID = 3.7021, Triplet = 0.0000, Center = 940.5680, i2t = 0.7465, t2i = 0.8666
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 80.74%
RANK5: 93.82%
RANK10: 97.43%
MAP: 86.58%
 New BEST Image model saved
[ArcFace] Confidence: 0.0587
[ArcFace] Confidence: 0.0618
[ArcFace] Confidence: 0.0669
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0505
[ArcFace] Confidence: 0.0590
[ArcFace] Confidence: 0.0613
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0508
[ArcFace] Confidence: 0.0566
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0582
[ArcFace] Confidence: 0.0648
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0605
[ArcFace] Confidence: 0.0599
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0612
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0616
[ArcFace] Confidence: 0.0573
[ArcFace] Confidence: 0.0554
[Epoch 14] Learning Rate: 0.000013
[Epoch 14] Running validation...
[Epoch 14] Loss Breakdown: ID = 3.6882, Triplet = 0.0022, Center = 935.2285, i2t = 0.9131, t2i = 0.9904
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 79.09%
RANK5: 93.72%
RANK10: 96.50%
MAP: 85.20%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0593
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0616
[ArcFace] Confidence: 0.0644
[ArcFace] Confidence: 0.0641
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0595
[ArcFace] Confidence: 0.0481
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0537
[Epoch 15] Learning Rate: 0.000012
[Epoch 15] Running validation...
[Epoch 15] Loss Breakdown: ID = 3.6164, Triplet = 0.0000, Center = 928.3021, i2t = 1.9015, t2i = 1.9808
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 81.57%
RANK5: 95.37%
RANK10: 98.25%
MAP: 87.31%
 New BEST Image model saved
[ArcFace] Confidence: 0.0650
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0593
[ArcFace] Confidence: 0.0645
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0603
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0596
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0547
[Epoch 16] Learning Rate: 0.000011
[Epoch 16] Running validation...
[Epoch 16] Loss Breakdown: ID = 3.6555, Triplet = 0.0091, Center = 926.4111, i2t = 1.5251, t2i = 1.6094
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 84.65%
RANK5: 95.16%
RANK10: 97.12%
MAP: 89.08%
 New BEST Image model saved
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0582
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0608
[ArcFace] Confidence: 0.0493
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0591
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0585
[ArcFace] Confidence: 0.0585
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0600
[ArcFace] Confidence: 0.0614
[ArcFace] Confidence: 0.0543
[ArcFace] Confidence: 0.0613
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0484
[Epoch 17] Learning Rate: 0.000009
[Epoch 17] Running validation...
[Epoch 17] Loss Breakdown: ID = 3.6923, Triplet = 0.0051, Center = 936.9905, i2t = 0.7892, t2i = 0.8666
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 83.01%
RANK5: 94.03%
RANK10: 97.73%
MAP: 87.96%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0494
[ArcFace] Confidence: 0.0594
[ArcFace] Confidence: 0.0571
[ArcFace] Confidence: 0.0662
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0487
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0644
[ArcFace] Confidence: 0.0576
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0579
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0636
[ArcFace] Confidence: 0.0616
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0558
[Epoch 18] Learning Rate: 0.000008
[Epoch 18] Running validation...
[Epoch 18] Loss Breakdown: ID = 3.6574, Triplet = 0.0032, Center = 929.9924, i2t = 1.5323, t2i = 1.6094
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 85.79%
RANK5: 95.78%
RANK10: 98.04%
MAP: 90.11%
 New BEST Image model saved
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0615
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0604
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0615
[ArcFace] Confidence: 0.0484
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0622
[ArcFace] Confidence: 0.0573
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0593
[ArcFace] Confidence: 0.0553
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0548
[Epoch 19] Learning Rate: 0.000007
[Epoch 19] Running validation...
[Epoch 19] Loss Breakdown: ID = 3.6086, Triplet = 0.0000, Center = 931.3403, i2t = 1.1538, t2i = 1.2380
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 84.65%
RANK5: 95.26%
RANK10: 97.43%
MAP: 89.42%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0591
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0607
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0635
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0625
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0589
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0510
[Epoch 20] Learning Rate: 0.000006
[Epoch 20] Running validation...
[Epoch 20] Loss Breakdown: ID = 3.5968, Triplet = 0.0000, Center = 938.0184, i2t = 1.6376, t2i = 1.7332
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 83.21%
RANK5: 94.03%
RANK10: 97.22%
MAP: 87.99%
No improvement in loss. Patience counter: 2/5
[ArcFace] Confidence: 0.0534
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0613
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0588
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0601
[ArcFace] Confidence: 0.0646
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0643
[ArcFace] Confidence: 0.0588
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0607
[ArcFace] Confidence: 0.0587
[ArcFace] Confidence: 0.0607
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0573
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0575
[Epoch 21] Learning Rate: 0.000005
[Epoch 21] Running validation...
[Epoch 21] Loss Breakdown: ID = 3.5559, Triplet = 0.0000, Center = 919.7514, i2t = 1.0203, t2i = 1.1142
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 83.63%
RANK5: 95.57%
RANK10: 98.46%
MAP: 88.93%
No improvement in loss. Patience counter: 3/5
[ArcFace] Confidence: 0.0576
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0614
[ArcFace] Confidence: 0.0616
[ArcFace] Confidence: 0.0487
[ArcFace] Confidence: 0.0558
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0577
[ArcFace] Confidence: 0.0606
[ArcFace] Confidence: 0.0610
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0543
[ArcFace] Confidence: 0.0633
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0607
[ArcFace] Confidence: 0.0534
[ArcFace] Confidence: 0.0645
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0646
[ArcFace] Confidence: 0.0540
[Epoch 22] Learning Rate: 0.000004
[Epoch 22] Running validation...
[Epoch 22] Loss Breakdown: ID = 3.5864, Triplet = 0.0020, Center = 920.7967, i2t = 0.8937, t2i = 0.9904
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 85.48%
RANK5: 95.16%
RANK10: 97.94%
MAP: 89.91%
No improvement in loss. Patience counter: 4/5
[ArcFace] Confidence: 0.0617
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0592
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0664
[ArcFace] Confidence: 0.0566
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0502
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0657
[ArcFace] Confidence: 0.0641
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0586
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0595
[ArcFace] Confidence: 0.0621
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0550
[Epoch 23] Learning Rate: 0.000003
[Epoch 23] Running validation...
[Epoch 23] Loss Breakdown: ID = 3.6129, Triplet = 0.0000, Center = 941.3977, i2t = 0.5276, t2i = 0.4952
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 85.89%
RANK5: 95.47%
RANK10: 97.63%
MAP: 90.11%
 New BEST Image model saved
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0632
[ArcFace] Confidence: 0.0467
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0590
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0659
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0620
[ArcFace] Confidence: 0.0568
[ArcFace] Confidence: 0.0607
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0543
[ArcFace] Confidence: 0.0595
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0500
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0604
[ArcFace] Confidence: 0.0524
[Epoch 24] Learning Rate: 0.000002
[Epoch 24] Running validation...
[Epoch 24] Loss Breakdown: ID = 3.5892, Triplet = 0.0000, Center = 937.0217, i2t = 1.2748, t2i = 1.3618
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 87.44%
RANK5: 95.47%
RANK10: 97.32%
MAP: 90.99%
 New BEST Image model saved
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0627
[ArcFace] Confidence: 0.0492
[ArcFace] Confidence: 0.0508
[ArcFace] Confidence: 0.0587
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0576
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0582
[ArcFace] Confidence: 0.0618
[ArcFace] Confidence: 0.0643
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0493
[ArcFace] Confidence: 0.0597
[ArcFace] Confidence: 0.0510
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0598
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0552
[Epoch 25] Learning Rate: 0.000002
[Epoch 25] Running validation...
[Epoch 25] Loss Breakdown: ID = 3.5465, Triplet = 0.0000, Center = 920.6422, i2t = 0.5791, t2i = 0.7428
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 86.71%
RANK5: 95.88%
RANK10: 97.53%
MAP: 90.72%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0638
[ArcFace] Confidence: 0.0591
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0596
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0620
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0585
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0632
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0533
[Epoch 26] Learning Rate: 0.000001
[Epoch 26] Running validation...
[Epoch 26] Loss Breakdown: ID = 3.6169, Triplet = 0.0000, Center = 948.7375, i2t = 0.5860, t2i = 0.7428
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 86.71%
RANK5: 95.26%
RANK10: 98.25%
MAP: 90.77%
No improvement in loss. Patience counter: 2/5
[ArcFace] Confidence: 0.0564
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0581
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0644
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0587
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0569
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0610
[ArcFace] Confidence: 0.0566
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0669
[ArcFace] Confidence: 0.0643
[ArcFace] Confidence: 0.0567
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0619
[Epoch 27] Learning Rate: 0.000001
[Epoch 27] Running validation...
[Epoch 27] Loss Breakdown: ID = 3.5974, Triplet = 0.0000, Center = 926.2529, i2t = 1.2646, t2i = 1.3618
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 87.85%
RANK5: 95.78%
RANK10: 97.32%
MAP: 91.31%
 New BEST Image model saved
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0498
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0576
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0654
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0574
[ArcFace] Confidence: 0.0648
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0655
[ArcFace] Confidence: 0.0675
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0591
[ArcFace] Confidence: 0.0609
[ArcFace] Confidence: 0.0572
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0567
[ArcFace] Confidence: 0.0550
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0576
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0512
[Epoch 28] Learning Rate: 0.000000
[Epoch 28] Running validation...
[Epoch 28] Loss Breakdown: ID = 3.5608, Triplet = 0.0000, Center = 926.7036, i2t = 1.5982, t2i = 1.7332
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 88.36%
RANK5: 95.88%
RANK10: 97.32%
MAP: 91.63%
 New BEST Image model saved
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0595
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0611
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0543
[ArcFace] Confidence: 0.0620
[ArcFace] Confidence: 0.0621
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0624
[ArcFace] Confidence: 0.0485
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0545
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0503
[ArcFace] Confidence: 0.0605
[ArcFace] Confidence: 0.0661
[ArcFace] Confidence: 0.0590
[ArcFace] Confidence: 0.0560
[ArcFace] Confidence: 0.0522
[Epoch 29] Learning Rate: 0.000000
[Epoch 29] Running validation...
[Epoch 29] Loss Breakdown: ID = 3.5784, Triplet = 0.0000, Center = 939.7247, i2t = 1.4391, t2i = 1.4856
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 87.54%
RANK5: 95.88%
RANK10: 97.32%
MAP: 91.24%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0579
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0553
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0605
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0598
[ArcFace] Confidence: 0.0620
[ArcFace] Confidence: 0.0483
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0593
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0567
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0498
[ArcFace] Confidence: 0.0557
[ArcFace] Confidence: 0.0604
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0649
[ArcFace] Confidence: 0.0502
[Epoch 30] Learning Rate: 0.000000
[Epoch 30] Running validation...
[Epoch 30] Loss Breakdown: ID = 3.5764, Triplet = 0.0000, Center = 940.9646, i2t = 1.1257, t2i = 1.2380
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 87.85%
RANK5: 95.47%
RANK10: 97.43%
MAP: 91.28%
No improvement in loss. Patience counter: 2/5
Restored BEST model for evaluation.
[Eval] Starting evaluation across all 10 splits (ReID style)
[DEBUG] CLIP Model = rn50 → Token Embed Dim: 512, Final LN Dim: 512
[DEBUG] PromptLearner proj layer = Linear | in: 512, out: 512
[DEBUG] Dummy Image Feature Shape: torch.Size([1, 1024])
[DEBUG] Text Feature Output (via proj) should match: 512
[WARNING] Feature dim mismatch! Image: 1024, Text: 512
BNNeck and ArcFace head registered (scale=20, margin=0.3)
CLIP text encoder unfrozen.
[Trainable] conv1.weight
[Trainable] bn1.weight
[Trainable] bn1.bias
[Trainable] conv2.weight
[Trainable] bn2.weight
[Trainable] bn2.bias
[Trainable] conv3.weight
[Trainable] bn3.weight
[Trainable] bn3.bias
[Trainable] layer1.0.conv1.weight
[Trainable] layer1.0.bn1.weight
[Trainable] layer1.0.bn1.bias
[Trainable] layer1.0.conv2.weight
[Trainable] layer1.0.bn2.weight
[Trainable] layer1.0.bn2.bias
[Trainable] layer1.0.conv3.weight
[Trainable] layer1.0.bn3.weight
[Trainable] layer1.0.bn3.bias
[Trainable] layer1.0.downsample.0.weight
[Trainable] layer1.0.downsample.1.weight
[Trainable] layer1.0.downsample.1.bias
[Trainable] layer1.1.conv1.weight
[Trainable] layer1.1.bn1.weight
[Trainable] layer1.1.bn1.bias
[Trainable] layer1.1.conv2.weight
[Trainable] layer1.1.bn2.weight
[Trainable] layer1.1.bn2.bias
[Trainable] layer1.1.conv3.weight
[Trainable] layer1.1.bn3.weight
[Trainable] layer1.1.bn3.bias
[Trainable] layer1.2.conv1.weight
[Trainable] layer1.2.bn1.weight
[Trainable] layer1.2.bn1.bias
[Trainable] layer1.2.conv2.weight
[Trainable] layer1.2.bn2.weight
[Trainable] layer1.2.bn2.bias
[Trainable] layer1.2.conv3.weight
[Trainable] layer1.2.bn3.weight
[Trainable] layer1.2.bn3.bias
[Trainable] layer2.0.conv1.weight
[Trainable] layer2.0.bn1.weight
[Trainable] layer2.0.bn1.bias
[Trainable] layer2.0.conv2.weight
[Trainable] layer2.0.bn2.weight
[Trainable] layer2.0.bn2.bias
[Trainable] layer2.0.conv3.weight
[Trainable] layer2.0.bn3.weight
[Trainable] layer2.0.bn3.bias
[Trainable] layer2.0.downsample.0.weight
[Trainable] layer2.0.downsample.1.weight
[Trainable] layer2.0.downsample.1.bias
[Trainable] layer2.1.conv1.weight
[Trainable] layer2.1.bn1.weight
[Trainable] layer2.1.bn1.bias
[Trainable] layer2.1.conv2.weight
[Trainable] layer2.1.bn2.weight
[Trainable] layer2.1.bn2.bias
[Trainable] layer2.1.conv3.weight
[Trainable] layer2.1.bn3.weight
[Trainable] layer2.1.bn3.bias
[Trainable] layer2.2.conv1.weight
[Trainable] layer2.2.bn1.weight
[Trainable] layer2.2.bn1.bias
[Trainable] layer2.2.conv2.weight
[Trainable] layer2.2.bn2.weight
[Trainable] layer2.2.bn2.bias
[Trainable] layer2.2.conv3.weight
[Trainable] layer2.2.bn3.weight
[Trainable] layer2.2.bn3.bias
[Trainable] layer2.3.conv1.weight
[Trainable] layer2.3.bn1.weight
[Trainable] layer2.3.bn1.bias
[Trainable] layer2.3.conv2.weight
[Trainable] layer2.3.bn2.weight
[Trainable] layer2.3.bn2.bias
[Trainable] layer2.3.conv3.weight
[Trainable] layer2.3.bn3.weight
[Trainable] layer2.3.bn3.bias
[Trainable] layer3.0.conv1.weight
[Trainable] layer3.0.bn1.weight
[Trainable] layer3.0.bn1.bias
[Trainable] layer3.0.conv2.weight
[Trainable] layer3.0.bn2.weight
[Trainable] layer3.0.bn2.bias
[Trainable] layer3.0.conv3.weight
[Trainable] layer3.0.bn3.weight
[Trainable] layer3.0.bn3.bias
[Trainable] layer3.0.downsample.0.weight
[Trainable] layer3.0.downsample.1.weight
[Trainable] layer3.0.downsample.1.bias
[Trainable] layer3.1.conv1.weight
[Trainable] layer3.1.bn1.weight
[Trainable] layer3.1.bn1.bias
[Trainable] layer3.1.conv2.weight
[Trainable] layer3.1.bn2.weight
[Trainable] layer3.1.bn2.bias
[Trainable] layer3.1.conv3.weight
[Trainable] layer3.1.bn3.weight
[Trainable] layer3.1.bn3.bias
[Trainable] layer3.2.conv1.weight
[Trainable] layer3.2.bn1.weight
[Trainable] layer3.2.bn1.bias
[Trainable] layer3.2.conv2.weight
[Trainable] layer3.2.bn2.weight
[Trainable] layer3.2.bn2.bias
[Trainable] layer3.2.conv3.weight
[Trainable] layer3.2.bn3.weight
[Trainable] layer3.2.bn3.bias
[Trainable] layer3.3.conv1.weight
[Trainable] layer3.3.bn1.weight
[Trainable] layer3.3.bn1.bias
[Trainable] layer3.3.conv2.weight
[Trainable] layer3.3.bn2.weight
[Trainable] layer3.3.bn2.bias
[Trainable] layer3.3.conv3.weight
[Trainable] layer3.3.bn3.weight
[Trainable] layer3.3.bn3.bias
[Trainable] layer3.4.conv1.weight
[Trainable] layer3.4.bn1.weight
[Trainable] layer3.4.bn1.bias
[Trainable] layer3.4.conv2.weight
[Trainable] layer3.4.bn2.weight
[Trainable] layer3.4.bn2.bias
[Trainable] layer3.4.conv3.weight
[Trainable] layer3.4.bn3.weight
[Trainable] layer3.4.bn3.bias
[Trainable] layer3.5.conv1.weight
[Trainable] layer3.5.bn1.weight
[Trainable] layer3.5.bn1.bias
[Trainable] layer3.5.conv2.weight
[Trainable] layer3.5.bn2.weight
[Trainable] layer3.5.bn2.bias
[Trainable] layer3.5.conv3.weight
[Trainable] layer3.5.bn3.weight
[Trainable] layer3.5.bn3.bias
[Trainable] layer4.0.conv1.weight
[Trainable] layer4.0.bn1.weight
[Trainable] layer4.0.bn1.bias
[Trainable] layer4.0.conv2.weight
[Trainable] layer4.0.bn2.weight
[Trainable] layer4.0.bn2.bias
[Trainable] layer4.0.conv3.weight
[Trainable] layer4.0.bn3.weight
[Trainable] layer4.0.bn3.bias
[Trainable] layer4.0.downsample.0.weight
[Trainable] layer4.0.downsample.1.weight
[Trainable] layer4.0.downsample.1.bias
[Trainable] layer4.1.conv1.weight
[Trainable] layer4.1.bn1.weight
[Trainable] layer4.1.bn1.bias
[Trainable] layer4.1.conv2.weight
[Trainable] layer4.1.bn2.weight
[Trainable] layer4.1.bn2.bias
[Trainable] layer4.1.conv3.weight
[Trainable] layer4.1.bn3.weight
[Trainable] layer4.1.bn3.bias
[Trainable] layer4.2.conv1.weight
[Trainable] layer4.2.bn1.weight
[Trainable] layer4.2.bn1.bias
[Trainable] layer4.2.conv2.weight
[Trainable] layer4.2.bn2.weight
[Trainable] layer4.2.bn2.bias
[Trainable] layer4.2.conv3.weight
[Trainable] layer4.2.bn3.weight
[Trainable] layer4.2.bn3.bias
[Trainable] attnpool.positional_embedding
[Trainable] attnpool.k_proj.weight
[Trainable] attnpool.k_proj.bias
[Trainable] attnpool.q_proj.weight
[Trainable] attnpool.q_proj.bias
[Trainable] attnpool.v_proj.weight
[Trainable] attnpool.v_proj.bias
[Trainable] attnpool.c_proj.weight
[Trainable] attnpool.c_proj.bias
Total trainable CLIP params: 102155689
[DEBUG] PromptLearner trainable params: 967680
[DEBUG] CLIP trainable params: 102155689
[Prompt] cached 890 frozen image feats
[Epoch 1] Avg Prompt Loss: 2.9602
new best prompt – 2.9602
[Epoch 2] Avg Prompt Loss: 2.5288
new best prompt – 2.5288
[Epoch 3] Avg Prompt Loss: 2.5813
[Epoch 4] Avg Prompt Loss: 2.2833
new best prompt – 2.2833
[Epoch 5] Avg Prompt Loss: 2.2630
new best prompt – 2.2630
[Epoch 6] Avg Prompt Loss: 2.1305
new best prompt – 2.1305
[Epoch 7] Avg Prompt Loss: 1.8955
new best prompt – 1.8955
[Epoch 8] Avg Prompt Loss: 1.9180
[Epoch 9] Avg Prompt Loss: 1.8697
new best prompt – 1.8697
[Epoch 10] Avg Prompt Loss: 1.7847
new best prompt – 1.7847
[Epoch 11] Avg Prompt Loss: 1.7507
new best prompt – 1.7507
[Epoch 12] Avg Prompt Loss: 1.5864
new best prompt – 1.5864
[Epoch 13] Avg Prompt Loss: 1.7598
[Epoch 14] Avg Prompt Loss: 1.7008
[Epoch 15] Avg Prompt Loss: 1.5344
new best prompt – 1.5344
[Epoch 16] Avg Prompt Loss: 1.6757
[Epoch 17] Avg Prompt Loss: 1.5848
[Epoch 18] Avg Prompt Loss: 1.4190
new best prompt – 1.4190
[Epoch 19] Avg Prompt Loss: 1.5391
[Epoch 20] Avg Prompt Loss: 1.5820
[Epoch 21] Avg Prompt Loss: 1.5417
[Epoch 22] Avg Prompt Loss: 1.6098
[Epoch 23] Avg Prompt Loss: 1.5055
[Epoch 24] Avg Prompt Loss: 1.5539
[Epoch 25] Avg Prompt Loss: 1.4773
[Epoch 26] Avg Prompt Loss: 1.6218
[Epoch 27] Avg Prompt Loss: 1.5914
[Epoch 28] Avg Prompt Loss: 1.5170
[Epoch 29] Avg Prompt Loss: 1.5428
[Epoch 30] Avg Prompt Loss: 1.5777
[DEBUG] CLIP Model = rn50 → Token Embed Dim: 512, Final LN Dim: 512
[DEBUG] PromptLearner proj layer = Linear | in: 512, out: 512
[DEBUG] Dummy Image Feature Shape: torch.Size([1, 1024])
[DEBUG] Text Feature Output (via proj) should match: 512
[WARNING] Feature dim mismatch! Image: 1024, Text: 512
BNNeck and ArcFace head registered (scale=20, margin=0.3)
CLIP text encoder unfrozen.
[Trainable] conv1.weight
[Trainable] bn1.weight
[Trainable] bn1.bias
[Trainable] conv2.weight
[Trainable] bn2.weight
[Trainable] bn2.bias
[Trainable] conv3.weight
[Trainable] bn3.weight
[Trainable] bn3.bias
[Trainable] layer1.0.conv1.weight
[Trainable] layer1.0.bn1.weight
[Trainable] layer1.0.bn1.bias
[Trainable] layer1.0.conv2.weight
[Trainable] layer1.0.bn2.weight
[Trainable] layer1.0.bn2.bias
[Trainable] layer1.0.conv3.weight
[Trainable] layer1.0.bn3.weight
[Trainable] layer1.0.bn3.bias
[Trainable] layer1.0.downsample.0.weight
[Trainable] layer1.0.downsample.1.weight
[Trainable] layer1.0.downsample.1.bias
[Trainable] layer1.1.conv1.weight
[Trainable] layer1.1.bn1.weight
[Trainable] layer1.1.bn1.bias
[Trainable] layer1.1.conv2.weight
[Trainable] layer1.1.bn2.weight
[Trainable] layer1.1.bn2.bias
[Trainable] layer1.1.conv3.weight
[Trainable] layer1.1.bn3.weight
[Trainable] layer1.1.bn3.bias
[Trainable] layer1.2.conv1.weight
[Trainable] layer1.2.bn1.weight
[Trainable] layer1.2.bn1.bias
[Trainable] layer1.2.conv2.weight
[Trainable] layer1.2.bn2.weight
[Trainable] layer1.2.bn2.bias
[Trainable] layer1.2.conv3.weight
[Trainable] layer1.2.bn3.weight
[Trainable] layer1.2.bn3.bias
[Trainable] layer2.0.conv1.weight
[Trainable] layer2.0.bn1.weight
[Trainable] layer2.0.bn1.bias
[Trainable] layer2.0.conv2.weight
[Trainable] layer2.0.bn2.weight
[Trainable] layer2.0.bn2.bias
[Trainable] layer2.0.conv3.weight
[Trainable] layer2.0.bn3.weight
[Trainable] layer2.0.bn3.bias
[Trainable] layer2.0.downsample.0.weight
[Trainable] layer2.0.downsample.1.weight
[Trainable] layer2.0.downsample.1.bias
[Trainable] layer2.1.conv1.weight
[Trainable] layer2.1.bn1.weight
[Trainable] layer2.1.bn1.bias
[Trainable] layer2.1.conv2.weight
[Trainable] layer2.1.bn2.weight
[Trainable] layer2.1.bn2.bias
[Trainable] layer2.1.conv3.weight
[Trainable] layer2.1.bn3.weight
[Trainable] layer2.1.bn3.bias
[Trainable] layer2.2.conv1.weight
[Trainable] layer2.2.bn1.weight
[Trainable] layer2.2.bn1.bias
[Trainable] layer2.2.conv2.weight
[Trainable] layer2.2.bn2.weight
[Trainable] layer2.2.bn2.bias
[Trainable] layer2.2.conv3.weight
[Trainable] layer2.2.bn3.weight
[Trainable] layer2.2.bn3.bias
[Trainable] layer2.3.conv1.weight
[Trainable] layer2.3.bn1.weight
[Trainable] layer2.3.bn1.bias
[Trainable] layer2.3.conv2.weight
[Trainable] layer2.3.bn2.weight
[Trainable] layer2.3.bn2.bias
[Trainable] layer2.3.conv3.weight
[Trainable] layer2.3.bn3.weight
[Trainable] layer2.3.bn3.bias
[Trainable] layer3.0.conv1.weight
[Trainable] layer3.0.bn1.weight
[Trainable] layer3.0.bn1.bias
[Trainable] layer3.0.conv2.weight
[Trainable] layer3.0.bn2.weight
[Trainable] layer3.0.bn2.bias
[Trainable] layer3.0.conv3.weight
[Trainable] layer3.0.bn3.weight
[Trainable] layer3.0.bn3.bias
[Trainable] layer3.0.downsample.0.weight
[Trainable] layer3.0.downsample.1.weight
[Trainable] layer3.0.downsample.1.bias
[Trainable] layer3.1.conv1.weight
[Trainable] layer3.1.bn1.weight
[Trainable] layer3.1.bn1.bias
[Trainable] layer3.1.conv2.weight
[Trainable] layer3.1.bn2.weight
[Trainable] layer3.1.bn2.bias
[Trainable] layer3.1.conv3.weight
[Trainable] layer3.1.bn3.weight
[Trainable] layer3.1.bn3.bias
[Trainable] layer3.2.conv1.weight
[Trainable] layer3.2.bn1.weight
[Trainable] layer3.2.bn1.bias
[Trainable] layer3.2.conv2.weight
[Trainable] layer3.2.bn2.weight
[Trainable] layer3.2.bn2.bias
[Trainable] layer3.2.conv3.weight
[Trainable] layer3.2.bn3.weight
[Trainable] layer3.2.bn3.bias
[Trainable] layer3.3.conv1.weight
[Trainable] layer3.3.bn1.weight
[Trainable] layer3.3.bn1.bias
[Trainable] layer3.3.conv2.weight
[Trainable] layer3.3.bn2.weight
[Trainable] layer3.3.bn2.bias
[Trainable] layer3.3.conv3.weight
[Trainable] layer3.3.bn3.weight
[Trainable] layer3.3.bn3.bias
[Trainable] layer3.4.conv1.weight
[Trainable] layer3.4.bn1.weight
[Trainable] layer3.4.bn1.bias
[Trainable] layer3.4.conv2.weight
[Trainable] layer3.4.bn2.weight
[Trainable] layer3.4.bn2.bias
[Trainable] layer3.4.conv3.weight
[Trainable] layer3.4.bn3.weight
[Trainable] layer3.4.bn3.bias
[Trainable] layer3.5.conv1.weight
[Trainable] layer3.5.bn1.weight
[Trainable] layer3.5.bn1.bias
[Trainable] layer3.5.conv2.weight
[Trainable] layer3.5.bn2.weight
[Trainable] layer3.5.bn2.bias
[Trainable] layer3.5.conv3.weight
[Trainable] layer3.5.bn3.weight
[Trainable] layer3.5.bn3.bias
[Trainable] layer4.0.conv1.weight
[Trainable] layer4.0.bn1.weight
[Trainable] layer4.0.bn1.bias
[Trainable] layer4.0.conv2.weight
[Trainable] layer4.0.bn2.weight
[Trainable] layer4.0.bn2.bias
[Trainable] layer4.0.conv3.weight
[Trainable] layer4.0.bn3.weight
[Trainable] layer4.0.bn3.bias
[Trainable] layer4.0.downsample.0.weight
[Trainable] layer4.0.downsample.1.weight
[Trainable] layer4.0.downsample.1.bias
[Trainable] layer4.1.conv1.weight
[Trainable] layer4.1.bn1.weight
[Trainable] layer4.1.bn1.bias
[Trainable] layer4.1.conv2.weight
[Trainable] layer4.1.bn2.weight
[Trainable] layer4.1.bn2.bias
[Trainable] layer4.1.conv3.weight
[Trainable] layer4.1.bn3.weight
[Trainable] layer4.1.bn3.bias
[Trainable] layer4.2.conv1.weight
[Trainable] layer4.2.bn1.weight
[Trainable] layer4.2.bn1.bias
[Trainable] layer4.2.conv2.weight
[Trainable] layer4.2.bn2.weight
[Trainable] layer4.2.bn2.bias
[Trainable] layer4.2.conv3.weight
[Trainable] layer4.2.bn3.weight
[Trainable] layer4.2.bn3.bias
[Trainable] attnpool.positional_embedding
[Trainable] attnpool.k_proj.weight
[Trainable] attnpool.k_proj.bias
[Trainable] attnpool.q_proj.weight
[Trainable] attnpool.q_proj.bias
[Trainable] attnpool.v_proj.weight
[Trainable] attnpool.v_proj.bias
[Trainable] attnpool.c_proj.weight
[Trainable] attnpool.c_proj.bias
Total trainable CLIP params: 102155689
[DEBUG] PromptLearner trainable params: 967680
[DEBUG] CLIP trainable params: 102155689
[Prompt] cached 890 frozen image feats
[Epoch 1] Avg Prompt Loss: 3.1020
new best prompt – 3.1020
[Epoch 2] Avg Prompt Loss: 2.7683
new best prompt – 2.7683
[Epoch 3] Avg Prompt Loss: 2.6419
new best prompt – 2.6419
[Epoch 4] Avg Prompt Loss: 2.3777
new best prompt – 2.3777
[Epoch 5] Avg Prompt Loss: 2.3080
new best prompt – 2.3080
[Epoch 6] Avg Prompt Loss: 2.1426
new best prompt – 2.1426
[Epoch 7] Avg Prompt Loss: 2.1548
[Epoch 8] Avg Prompt Loss: 1.9122
new best prompt – 1.9122
[Epoch 9] Avg Prompt Loss: 1.8682
new best prompt – 1.8682
[Epoch 10] Avg Prompt Loss: 1.7352
new best prompt – 1.7352
[Epoch 11] Avg Prompt Loss: 1.7124
new best prompt – 1.7124
[Epoch 12] Avg Prompt Loss: 1.7316
[Epoch 13] Avg Prompt Loss: 1.7064
new best prompt – 1.7064
[Epoch 14] Avg Prompt Loss: 1.7264
[Epoch 15] Avg Prompt Loss: 1.5889
new best prompt – 1.5889
[Epoch 16] Avg Prompt Loss: 1.6979
[Epoch 17] Avg Prompt Loss: 1.5875
new best prompt – 1.5875
[Epoch 18] Avg Prompt Loss: 1.4850
new best prompt – 1.4850
[Epoch 19] Avg Prompt Loss: 1.5800
[Epoch 20] Avg Prompt Loss: 1.6179
[Epoch 21] Avg Prompt Loss: 1.5451
[Epoch 22] Avg Prompt Loss: 1.4080
new best prompt – 1.4080
[Epoch 23] Avg Prompt Loss: 1.5630
[Epoch 24] Avg Prompt Loss: 1.5158
[Epoch 25] Avg Prompt Loss: 1.5934
[Epoch 26] Avg Prompt Loss: 1.5745
[Epoch 27] Avg Prompt Loss: 1.5434
[Epoch 28] Avg Prompt Loss: 1.6127
[Epoch 29] Avg Prompt Loss: 1.5623
[Epoch 30] Avg Prompt Loss: 1.5445
[DEBUG] CLIP Model = rn50 → Token Embed Dim: 512, Final LN Dim: 512
[DEBUG] PromptLearner proj layer = Linear | in: 512, out: 512
[DEBUG] Dummy Image Feature Shape: torch.Size([1, 1024])
[DEBUG] Text Feature Output (via proj) should match: 512
[WARNING] Feature dim mismatch! Image: 1024, Text: 512
BNNeck and ArcFace head registered (scale=20, margin=0.3)
CLIP text encoder unfrozen.
Unfroze RN50 layers: layer3 and layer4
Total trainable CLIP params: 85901897
[DEBUG] PromptLearner trainable params: 967680
[DEBUG] CLIP trainable params: 85901897
[Prompt] cached 890 frozen image feats
[Epoch 1] Avg Prompt Loss: 3.1349
new best prompt – 3.1349
[Epoch 2] Avg Prompt Loss: 2.7355
new best prompt – 2.7355
[Epoch 3] Avg Prompt Loss: 2.6187
new best prompt – 2.6187
[Epoch 4] Avg Prompt Loss: 2.4577
new best prompt – 2.4577
[Epoch 5] Avg Prompt Loss: 2.0930
new best prompt – 2.0930
[Epoch 6] Avg Prompt Loss: 2.0755
new best prompt – 2.0755
[Epoch 7] Avg Prompt Loss: 2.0777
[Epoch 8] Avg Prompt Loss: 1.9340
new best prompt – 1.9340
[Epoch 9] Avg Prompt Loss: 1.7491
new best prompt – 1.7491
[Epoch 10] Avg Prompt Loss: 1.7434
new best prompt – 1.7434
[Epoch 11] Avg Prompt Loss: 1.7163
new best prompt – 1.7163
[Epoch 12] Avg Prompt Loss: 1.6705
new best prompt – 1.6705
[Epoch 13] Avg Prompt Loss: 1.7028
[Epoch 14] Avg Prompt Loss: 1.5260
new best prompt – 1.5260
[Epoch 15] Avg Prompt Loss: 1.7745
[Epoch 16] Avg Prompt Loss: 1.6108
[Epoch 17] Avg Prompt Loss: 1.6060
[Epoch 18] Avg Prompt Loss: 1.6660
[Epoch 19] Avg Prompt Loss: 1.5050
new best prompt – 1.5050
[Epoch 20] Avg Prompt Loss: 1.4920
new best prompt – 1.4920
[Epoch 21] Avg Prompt Loss: 1.5615
[Epoch 22] Avg Prompt Loss: 1.5264
[Epoch 23] Avg Prompt Loss: 1.4219
new best prompt – 1.4219
[Epoch 24] Avg Prompt Loss: 1.5730
[Epoch 25] Avg Prompt Loss: 1.5315
[Epoch 26] Avg Prompt Loss: 1.5291
[Epoch 27] Avg Prompt Loss: 1.4832
[Epoch 28] Avg Prompt Loss: 1.6390
[Epoch 29] Avg Prompt Loss: 1.5434
[Epoch 30] Avg Prompt Loss: 1.4653
[DEBUG] CLIP Model = rn50 → Token Embed Dim: 512, Final LN Dim: 512
[DEBUG] PromptLearner proj layer = Linear | in: 512, out: 512
[DEBUG] Dummy Image Feature Shape: torch.Size([1, 1024])
[DEBUG] Text Feature Output (via proj) should match: 512
[WARNING] Feature dim mismatch! Image: 1024, Text: 512
BNNeck and ArcFace head registered (scale=20, margin=0.3)
Total trainable CLIP params: 102155689
[DEBUG] PromptLearner trainable params: 967680
[DEBUG] CLIP trainable params: 102155689
[Prompt] cached 890 frozen image feats
[Epoch 1] Avg Prompt Loss: 2.9325
new best prompt – 2.9325
[Epoch 2] Avg Prompt Loss: 3.0584
[Epoch 3] Avg Prompt Loss: 2.5001
new best prompt – 2.5001
[Epoch 4] Avg Prompt Loss: 2.3315
new best prompt – 2.3315
[Epoch 5] Avg Prompt Loss: 2.1244
new best prompt – 2.1244
[Epoch 6] Avg Prompt Loss: 2.0576
new best prompt – 2.0576
[Epoch 7] Avg Prompt Loss: 1.9356
new best prompt – 1.9356
[Epoch 8] Avg Prompt Loss: 2.1151
[Epoch 9] Avg Prompt Loss: 1.8145
new best prompt – 1.8145
[Epoch 10] Avg Prompt Loss: 1.7826
new best prompt – 1.7826
[Epoch 11] Avg Prompt Loss: 1.8319
[Epoch 12] Avg Prompt Loss: 1.8653
[Epoch 13] Avg Prompt Loss: 1.5632
new best prompt – 1.5632
[Epoch 14] Avg Prompt Loss: 1.6934
[Epoch 15] Avg Prompt Loss: 1.4958
new best prompt – 1.4958
[Epoch 16] Avg Prompt Loss: 1.5928
[Epoch 17] Avg Prompt Loss: 1.5481
[Epoch 18] Avg Prompt Loss: 1.5087
[Epoch 19] Avg Prompt Loss: 1.5738
[Epoch 20] Avg Prompt Loss: 1.5687
[Epoch 21] Avg Prompt Loss: 1.6436
[Epoch 22] Avg Prompt Loss: 1.5259
[Epoch 23] Avg Prompt Loss: 1.4569
new best prompt – 1.4569
[Epoch 24] Avg Prompt Loss: 1.6926
[Epoch 25] Avg Prompt Loss: 1.5732
[Epoch 26] Avg Prompt Loss: 1.4858
[Epoch 27] Avg Prompt Loss: 1.4193
new best prompt – 1.4193
[Epoch 28] Avg Prompt Loss: 1.4228
[Epoch 29] Avg Prompt Loss: 1.5308
[Epoch 30] Avg Prompt Loss: 1.4278
Unfroze RN50 layers: layer3 and layer4
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0570
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0553
[ArcFace] Confidence: 0.0494
[ArcFace] Confidence: 0.0563
[ArcFace] Confidence: 0.0590
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0494
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0575
[ArcFace] Confidence: 0.0500
[ArcFace] Confidence: 0.0534
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0561
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0582
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0539
[Epoch 1] Learning Rate: 0.000006
[Epoch 1] Running validation...
[Epoch 1] Loss Breakdown: ID = 4.2704, Triplet = 0.1411, Center = 956.3503, i2t = 1.6755, t2i = 1.6094
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 51.08%
RANK5: 70.75%
RANK10: 79.81%
MAP: 60.77%
 New BEST Image model saved
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0493
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0510
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0491
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0571
[ArcFace] Confidence: 0.0591
[Epoch 2] Learning Rate: 0.000015
[Epoch 2] Running validation...
[Epoch 2] Loss Breakdown: ID = 4.2685, Triplet = 0.1364, Center = 961.9865, i2t = 1.3488, t2i = 1.3618
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 50.26%
RANK5: 76.21%
RANK10: 85.38%
MAP: 62.05%
No improvement in loss. Patience counter: 1/5
[ArcFace] Confidence: 0.0490
[ArcFace] Confidence: 0.0554
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0596
[ArcFace] Confidence: 0.0578
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0497
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0486
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0486
[ArcFace] Confidence: 0.0526
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0504
[Epoch 3] Learning Rate: 0.000020
[Epoch 3] Running validation...
[Epoch 3] Loss Breakdown: ID = 4.2424, Triplet = 0.1015, Center = 957.2147, i2t = 1.2340, t2i = 1.2380
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 63.03%
RANK5: 82.18%
RANK10: 90.42%
MAP: 72.05%
 New BEST Image model saved
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0482
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0497
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0495
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0494
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0583
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0522
[Epoch 4] Learning Rate: 0.000020
[Epoch 4] Running validation...
[Epoch 4] Loss Breakdown: ID = 4.2252, Triplet = 0.1128, Center = 970.4731, i2t = 2.1040, t2i = 2.1046
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 70.13%
RANK5: 89.29%
RANK10: 95.88%
MAP: 78.62%
 New BEST Image model saved
[ArcFace] Confidence: 0.0505
[ArcFace] Confidence: 0.0501
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0498
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0544
[ArcFace] Confidence: 0.0504
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0502
[ArcFace] Confidence: 0.0513
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0551
[ArcFace] Confidence: 0.0531
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0481
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0510
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0554
[Epoch 5] Learning Rate: 0.000020
[Epoch 5] Running validation...
[Epoch 5] Loss Breakdown: ID = 4.2017, Triplet = 0.0382, Center = 969.6254, i2t = 0.8163, t2i = 0.8666
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 74.67%
RANK5: 92.17%
RANK10: 95.98%
MAP: 82.43%
 New BEST Image model saved
[ArcFace] Confidence: 0.0495
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0487
[ArcFace] Confidence: 0.0505
[ArcFace] Confidence: 0.0532
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0534
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0530
[ArcFace] Confidence: 0.0552
[ArcFace] Confidence: 0.0584
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0525
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0503
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0528
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0508
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0562
[ArcFace] Confidence: 0.0479
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0556
[Epoch 6] Learning Rate: 0.000019
[Epoch 6] Running validation...
[Epoch 6] Loss Breakdown: ID = 4.1951, Triplet = 0.1012, Center = 970.3645, i2t = 2.0704, t2i = 1.9808
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 75.70%
RANK5: 93.51%
RANK10: 97.32%
MAP: 83.23%
 New BEST Image model saved
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0559
[ArcFace] Confidence: 0.0491
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0524
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0535
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0565
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0507
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0508
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0556
[ArcFace] Confidence: 0.0538
[ArcFace] Confidence: 0.0542
[ArcFace] Confidence: 0.0523
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0585
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0472
[ArcFace] Confidence: 0.0480
[Epoch 7] Learning Rate: 0.000019
[Epoch 7] Running validation...
[Epoch 7] Loss Breakdown: ID = 4.1627, Triplet = 0.0090, Center = 958.3462, i2t = 0.6758, t2i = 0.7428
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 76.83%
RANK5: 94.44%
RANK10: 98.04%
MAP: 84.35%
 New BEST Image model saved
[ArcFace] Confidence: 0.0573
[ArcFace] Confidence: 0.0547
[ArcFace] Confidence: 0.0496
[ArcFace] Confidence: 0.0491
[ArcFace] Confidence: 0.0555
[ArcFace] Confidence: 0.0491
[ArcFace] Confidence: 0.0549
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0510
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0502
[ArcFace] Confidence: 0.0508
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0541
[ArcFace] Confidence: 0.0503
[ArcFace] Confidence: 0.0580
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0537
[ArcFace] Confidence: 0.0548
[ArcFace] Confidence: 0.0499
[ArcFace] Confidence: 0.0536
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0498
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0554
[Epoch 8] Learning Rate: 0.000018
[Epoch 8] Running validation...
[Epoch 8] Loss Breakdown: ID = 4.1488, Triplet = 0.0465, Center = 961.3364, i2t = 1.1508, t2i = 1.1142
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 78.06%
RANK5: 94.54%
RANK10: 97.63%
MAP: 85.08%
 New BEST Image model saved
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0514
[ArcFace] Confidence: 0.0529
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0543
[ArcFace] Confidence: 0.0517
[ArcFace] Confidence: 0.0522
[ArcFace] Confidence: 0.0511
[ArcFace] Confidence: 0.0512
[ArcFace] Confidence: 0.0518
[ArcFace] Confidence: 0.0516
[ArcFace] Confidence: 0.0582
[ArcFace] Confidence: 0.0560
[ArcFace] Confidence: 0.0519
[ArcFace] Confidence: 0.0533
[ArcFace] Confidence: 0.0471
[ArcFace] Confidence: 0.0482
[ArcFace] Confidence: 0.0521
[ArcFace] Confidence: 0.0540
[ArcFace] Confidence: 0.0509
[ArcFace] Confidence: 0.0539
[ArcFace] Confidence: 0.0520
[ArcFace] Confidence: 0.0515
[ArcFace] Confidence: 0.0527
[ArcFace] Confidence: 0.0546
[ArcFace] Confidence: 0.0506
[ArcFace] Confidence: 0.0581
[Epoch 9] Learning Rate: 0.000018
[Epoch 9] Running validation...
[Epoch 9] Loss Breakdown: ID = 4.1170, Triplet = 0.0000, Center = 967.0274, i2t = 0.9565, t2i = 1.1142
[Validation] Extracting features...
[Validation] Evaluating ranks and mAP...

[ReID Validation]
RANK1: 78.48%
RANK5: 95.47%
RANK10: 97.53%
MAP: 85.74%
 New BEST Image model saved
