# ğŸ§ª Stage 3 â€” PromptSG Integration (CLIP-FH)

This folder implements **Stage 3** of the CLIP-FH pipeline, focused on joint training using **PromptSG**: a semantic-guided prompt tuning strategy that combines pseudo-token generation, multimodal fusion, and contrastive ReID losses.

---

## ğŸ“ Folder Contents

| File                            | Description |
|----------------------------------|-------------|
| `train_stage3_promptsg.py`       | Main training script using PromptSG methodology: joint pseudo-token learning, prompt composition, cross-attention, and multi-loss optimization. |
| `eval_stage3_promptsg.py`        | Evaluation runner for ReID-style Rank@K and mAP metrics using the best model across 10 query-gallery splits. |
| `ANLAYSIS REPORT_FORMATTED.md`   | Clean tabular summary of all PromptSG versions (`v1` to `v11`) for both ViT-B/16 and RN50, with configuration changes and results. |
| `ANLAYSIS REPORT_UNFORMATTED.md` | Full experimental notes, YAML config details, motivations, and architecture insights across all runs. |

---

## ğŸ—ï¸ Script Breakdown

### ğŸ”§ `train_stage3_promptsg.py`

Implements PromptSG pipeline:
- Builds CLIP model with frozen text encoder
- Learns **TextualInversionMLP** for pseudo-token generation
- Dynamically composes prompts with pseudo tokens
- Applies **MultiModalInteraction** (cross-attention & transformers)
- Uses configurable classifier: `linear` or `BNNeck + ArcFace`
- Supports three loss types: CrossEntropy, Triplet, SupCon

ğŸ”§ YAML fields include:
```yaml
classifier: arcface
bnneck_dim: 256
transformer_layers: 3
prompt_template: "A captured frame showing a person's {aspect} hand."
loss_id_weight: 1.0
loss_tri_weight: 1.0
supcon_loss_weight: 1.0
````

ğŸ§ª Example usage:

```bash
python train_stage3_promptsg.py --config configs/train_stage3_promptsg/train_stage3_vitb16_11k_dorsal_r.yml
```

---

### ğŸ§ª `eval_stage3_promptsg.py`

Launches ReID-style evaluation using the trained model:

* Supports all 10 query-gallery splits
* Logs Rank-1, Rank-5, Rank-10, and mAP
* Works with best saved `_BEST.pth` checkpoint

ğŸ“Œ Usage:

```bash
python eval_stage3_promptsg.py configs/eval_stage3_promptsg/eval_stage3_vitb16_11k_dorsal_r.yml
```

---

## ğŸ“Š Model Versions (`v1`â€“`v11`)

All versions are detailed in `ANLAYSIS REPORT_FORMATTED.md`:

| Version | Highlights                            | Best Result (ViT-B/16)     |
| ------- | ------------------------------------- | -------------------------- |
| v1      | Baseline CE + Triplet + Linear Head   | R1 62.38 / mAP 71.57       |
| v4      | BNNeck + ArcFace Head                 | R1 42.25 / mAP 54.32       |
| v5      | Paper-faithful MLP + prompt fusion    | R1 41.45 / mAP 52.09       |
| v6      | Grad clip â†“, LR â†“ (1e-6) â†’ huge boost | R1 80.83 / mAP 86.63       |
| v8      | BNNeck dim 1024 + no Cosine LR        | â­ **R1 85.86 / mAP 89.99** |
| v11     | Portrait resize (224Ã—128)             | R1 81.59 / mAP 86.93       |

> For RN50 track, version v8 also achieved the peak: R1 61.23 / mAP 69.75.

---

## ğŸ§  Technical Highlights

* âœ… Fully frozen CLIP text encoder
* âœ… Supports pseudo-token learning via `TextualInversionMLP`
* âœ… Prompt composition: `"A captured frame showing a personâ€™s {aspect} hand"`
* âœ… Cross-attention between image and prompt embeddings
* âœ… ArcFace classifier with BNNeck + optional reduction
* âœ… Rank\@K and mAP evaluation across all splits

---

## ğŸ”¬ Key Takeaways

| Insight                                                         | Explanation                                                       |
| --------------------------------------------------------------- | ----------------------------------------------------------------- |
| âœ… **Contrastive-only** (Triplet + SupCon) works better for RN50 | ViT collapsed on it (v3), RN50 peaked (v3)                        |
| âœ… **BNNeck + ArcFace** needs tuning                             | Improves results only when paired with lower LR and gradient norm |
| ğŸ“‰ **Portrait resize** hurts performance                        | v11 drop \~3â€“4 pp mAP                                             |
| âš–ï¸ **Gradient clipping and tiny LR** stabilize training         | v6â€“v8 gains                                                       |

---

## ğŸ“‚ Result Files

* CSV files: `result_logs/stage3_vitb16_remarks.csv`, `stage3_rn50_remarks.csv`
* Model checkpoints: Saved under `save_dir` as `_BEST.pth`
* Evaluation logs: Written to `eval_logs/`

---

## ğŸ“¬ Contact

For further clarifications, contact [babupallam@gmail.com](mailto:babupallam@gmail.com)

```
