experiment: stage2a_prompt_vitb16_11k_dorsal_r
dataset: 11k
aspect: dorsal_r
model: vitb16
variant: clipid

n_ctx: 8
ctx_init: "a hand" # person,  identity, biometric, individual, "hand image"
prompt_template: "A photo of {}'s {aspect} hand for identification."  # Dynamic prompt based on identity and aspect
freeze_text_encoder: false
early_stop_prompt_norm: 1.2e-3

batch_size: 32
epochs: 30
lr: 0.0001

output_dir: train_logs/
save_dir: saved_models/

loss_list: ["supcon"]   # CLIP-ReID uses supcon_loss for prompt tuning






