
# ðŸ› ï¸ Utilities â€” CLIP-FH Project

The `utils/` directory provides reusable modules and helper functions essential to training, evaluation, logging, model handling, and data processing throughout the CLIP-FH pipeline.

---

## ðŸ“ Directory Structure

```

utils/
â”œâ”€â”€ loss/                         # All loss function definitions
â”‚   â”œâ”€â”€ archives/                 # Deprecated or legacy loss function versions
â”‚   â”œâ”€â”€ arcface.py               # ArcFace loss (angular margin softmax)
â”‚   â”œâ”€â”€ center\_loss.py           # Center loss for feature compactness
â”‚   â”œâ”€â”€ cross\_entropy\_loss.py    # Label-smoothing CrossEntropy loss
â”‚   â”œâ”€â”€ make\_loss.py             # Factory method to construct combined losses
â”‚   â”œâ”€â”€ supcon.py                # Supervised Contrastive loss (SupCon)
â”‚   â”œâ”€â”€ triplet\_loss.py          # Triplet loss with optional margin
â”‚   â””â”€â”€ README.md                # Loss module documentation
â”‚
â”œâ”€â”€ clip\_patch.py                # Wrapper and patch for modifying CLIP modules
â”œâ”€â”€ dataloaders.py               # Dataset loading and PK sampling logic
â”œâ”€â”€ device\_selection.py          # Auto-detect CUDA or MPS device
â”œâ”€â”€ eval\_utils.py                # Functions for ReID-style evaluation (Rank\@K, mAP)
â”œâ”€â”€ feature\_cache.py             # Embedding cache utils for quick eval or zero-shot
â”œâ”€â”€ logger.py                    # CSV and TXT logger utilities
â”œâ”€â”€ naming.py                    # Filename and experiment naming helpers
â”œâ”€â”€ save\_load\_models.py          # Model checkpoint save/load logic
â”œâ”€â”€ train\_helpers.py             # Training logic wrappers and hooks
â”œâ”€â”€ transforms.py                # Image transform pipelines
â””â”€â”€ README.md                    # You are here ðŸ“˜

````

---

## ðŸ” Key Components

### ðŸ”¹ `loss/`
Contains all the loss functions used across the pipeline:
- `arcface.py`: Implements ArcFace margin-based classifier.
- `center_loss.py`: Minimizes intra-class variance in embedding space.
- `triplet_loss.py`: Distance-based learning with anchor, positive, and negative.
- `supcon.py`: Implements Supervised Contrastive Loss for PÃ—K sampled batches.
- `make_loss.py`: Centralized function to combine multiple loss terms per config.
- `cross_entropy_loss.py`: Standard CE loss with optional smoothing.
- `archives/`: Backup versions of older loss implementations.

> Use `make_loss()` to dynamically assemble loss functions based on config.

---

### ðŸ”¹ Other Utility Scripts

- `clip_patch.py`: Custom patches and wrappers to modify OpenAI's CLIP modules (e.g., freezing layers, BNNeck).
- `dataloaders.py`: Includes dataset creation, PK sampling, class-balanced batch logic.
- `eval_utils.py`: mAP and Rank@K computation logic for ReID evaluation.
- `feature_cache.py`: Saves and loads image/text features for fast zero-shot or ablation testing.
- `logger.py`: Dual-mode logger writing to both CSV and console/txt.
- `train_helpers.py`: Hooks and helpers for loss scaling, gradient clipping, metric tracking.
- `save_load_models.py`: Load/save checkpoint handlers including best-model logic.
- `transforms.py`: Defines training/validation transforms (augmentations, normalization).
- `device_selection.py`: Automatically selects between CPU, CUDA, or MPS for PyTorch.

---

## âœ… Usage Example

You can import any utility in your training or evaluation script like so:

```python
from utils.loss.make_loss import make_loss
from utils.dataloaders import create_dataloader
from utils.eval_utils import compute_rank_k_accuracy
````

---

## ðŸ“¬ Contact

For questions or suggestions, contact: [babupallam@gmail.com](mailto:babupallam@gmail.com)

```
