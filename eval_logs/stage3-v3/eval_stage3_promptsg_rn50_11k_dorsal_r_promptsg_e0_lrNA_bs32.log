Evaluation Log
==================================================
Config      : C:\Users\P2849288\OneDrive - De Montfort University\MSC PROJECT\BABU PALLAM\CLIP-FH\configs\eval_stage3_promptsg\eval_stage3_rn50_11k_dorsal_r.yml
Experiment  : eval_stage3_promptsg
Model       : rn50
Variant     : promptsg
Dataset     : 11k
Aspect      : dorsal_r
Model Path  : saved_models/stage3_promptsg_rn50_11k_dorsal_r_promptsg_e20_lrNA_bs32_BEST.pth
==================================================

Device: cuda
Loading fine-tuned model from: saved_models/stage3_promptsg_rn50_11k_dorsal_r_promptsg_e20_lrNA_bs32_BEST.pth
[PromptSG] PromptSG checkpoint loaded
Checkpoint restored from epoch 2
Checkpoint metadata: {'stage': 'promptsg', 'save_time': '2025-04-19T08:01:31.955192', 'clip_variant': 'rn50', 'dataset': '11k'}
[PromptSG] Detected PromptSG checkpoint  rebuilding submodules

Split 1/10
Evaluation Metrics:
   Rank-1 : 70.34%
   Rank-5 : 88.16%
   Rank-10: 92.69%
   mAP    : 77.82%
Time Taken     : 34.67s

Split 2/10
Evaluation Metrics:
   Rank-1 : 63.85%
   Rank-5 : 80.02%
   Rank-10: 85.68%
   mAP    : 71.23%
Time Taken     : 32.74s

Split 3/10
Evaluation Metrics:
   Rank-1 : 70.55%
   Rank-5 : 85.58%
   Rank-10: 91.25%
   mAP    : 77.77%
Time Taken     : 33.20s

Split 4/10
Evaluation Metrics:
   Rank-1 : 66.74%
   Rank-5 : 85.48%
   Rank-10: 91.56%
   mAP    : 74.96%
Time Taken     : 31.52s

Split 5/10
Evaluation Metrics:
   Rank-1 : 70.65%
   Rank-5 : 86.51%
   Rank-10: 91.76%
   mAP    : 77.62%
Time Taken     : 31.41s

Split 6/10
Evaluation Metrics:
   Rank-1 : 69.93%
   Rank-5 : 85.68%
   Rank-10: 91.04%
   mAP    : 76.82%
Time Taken     : 31.59s

Split 7/10
Evaluation Metrics:
   Rank-1 : 67.25%
   Rank-5 : 83.32%
   Rank-10: 89.29%
   mAP    : 74.78%
Time Taken     : 31.40s

Split 8/10
Evaluation Metrics:
   Rank-1 : 70.13%
   Rank-5 : 84.35%
   Rank-10: 90.53%
   mAP    : 76.81%
Time Taken     : 31.37s

Split 9/10
Evaluation Metrics:
   Rank-1 : 69.72%
   Rank-5 : 84.35%
   Rank-10: 91.66%
   mAP    : 76.47%
Time Taken     : 31.37s

Split 10/10
Evaluation Metrics:
   Rank-1 : 70.75%
   Rank-5 : 87.85%
   Rank-10: 93.82%
   mAP    : 78.47%
Time Taken     : 31.18s

Final Averaged Results Across All Splits:
Rank-1 Accuracy : 68.99%
Rank-5 Accuracy : 85.13%
Rank-10 Accuracy: 90.93%
Mean AP         : 76.28%

Log saved to: eval_logs/eval_stage3_promptsg_rn50_11k_dorsal_r_promptsg_e0_lrNA_bs32.log
