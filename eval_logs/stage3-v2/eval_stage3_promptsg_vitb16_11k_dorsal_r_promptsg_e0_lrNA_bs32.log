Evaluation Log
==================================================
Config      : C:\Users\P2849288\OneDrive - De Montfort University\MSC PROJECT\BABU PALLAM\CLIP-FH\configs\eval_stage3_promptsg\eval_stage3_vitb16_11k_dorsal_r.yml
Experiment  : eval_stage3_promptsg
Model       : vitb16
Variant     : promptsg
Dataset     : 11k
Aspect      : dorsal_r
Model Path  : saved_models/stage3_promptsg_vitb16_11k_dorsal_r_promptsg_e20_lrNA_bs32_BEST.pth
==================================================

Device: cuda
Loading fine-tuned model from: saved_models/stage3_promptsg_vitb16_11k_dorsal_r_promptsg_e20_lrNA_bs32_BEST.pth
[PromptSG] PromptSG checkpoint loaded
Checkpoint restored from epoch 1
Checkpoint metadata: {'stage': 'promptsg', 'save_time': '2025-04-19T07:01:06.762974', 'clip_variant': 'vitb16', 'dataset': '11k'}
[PromptSG] Detected PromptSG checkpoint  rebuilding submodules

Split 1/10
Evaluation Metrics:
   Rank-1 : 36.15%
   Rank-5 : 60.76%
   Rank-10: 71.06%
   mAP    : 47.52%
Time Taken     : 33.83s

Split 2/10
Evaluation Metrics:
   Rank-1 : 34.71%
   Rank-5 : 57.05%
   Rank-10: 71.47%
   mAP    : 45.36%
Time Taken     : 31.79s

Split 3/10
Evaluation Metrics:
   Rank-1 : 39.44%
   Rank-5 : 60.14%
   Rank-10: 70.75%
   mAP    : 49.50%
Time Taken     : 31.80s

Split 4/10
Evaluation Metrics:
   Rank-1 : 36.97%
   Rank-5 : 58.50%
   Rank-10: 70.85%
   mAP    : 47.93%
Time Taken     : 31.76s

Split 5/10
Evaluation Metrics:
   Rank-1 : 38.72%
   Rank-5 : 60.66%
   Rank-10: 71.58%
   mAP    : 49.11%
Time Taken     : 31.99s

Split 6/10
Evaluation Metrics:
   Rank-1 : 38.83%
   Rank-5 : 61.79%
   Rank-10: 73.53%
   mAP    : 49.49%
Time Taken     : 31.77s

Split 7/10
Evaluation Metrics:
   Rank-1 : 35.84%
   Rank-5 : 57.78%
   Rank-10: 70.13%
   mAP    : 46.89%
Time Taken     : 32.02s

Split 8/10
Evaluation Metrics:
   Rank-1 : 36.15%
   Rank-5 : 60.25%
   Rank-10: 72.61%
   mAP    : 47.82%
Time Taken     : 31.95s

Split 9/10
Evaluation Metrics:
   Rank-1 : 33.88%
   Rank-5 : 59.73%
   Rank-10: 72.30%
   mAP    : 46.36%
Time Taken     : 31.79s

Split 10/10
Evaluation Metrics:
   Rank-1 : 33.78%
   Rank-5 : 60.87%
   Rank-10: 74.36%
   mAP    : 46.36%
Time Taken     : 31.78s

Final Averaged Results Across All Splits:
Rank-1 Accuracy : 36.45%
Rank-5 Accuracy : 59.75%
Rank-10 Accuracy: 71.86%
Mean AP         : 47.64%

Log saved to: eval_logs/eval_stage3_promptsg_vitb16_11k_dorsal_r_promptsg_e0_lrNA_bs32.log
